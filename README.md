# Reviewer Zero

自律型・投稿前査読オーケストレーター「Reviewer Zero — IEICE Letter Preflight & Oral Defense」

---

## 🚀 Quick Start

### フロントエンドの起動（Docker Compose）

```bash
# 1. リポジトリをクローン
git clone <repository-url>
cd front

# 2. Docker Compose で起動（初回は自動ビルド）
docker compose up --build

# 3. ブラウザでアクセス
open http://localhost:3000
```

### よく使うコマンド

```bash
# バックグラウンドで起動
docker compose up -d --build

# ログを見る
docker compose logs -f frontend

# 停止
docker compose down

# コンテナ・イメージを完全削除してリセット
docker compose down --rmi all -v
```

### 開発モード（ホットリロード対応）

`docker compose up` した状態で `front/src/` 内のファイルを編集すると、自動でブラウザに反映されます。

---

## 0. 文書情報

* 文書名：要件定義書（Reviewer Zero）
* 版：v0.9（ドラフト）
* 作成日：2026-01-30
* 想定用途：

  * ハッカソン提出用のMVP開発
  * 学会（IEICE等）への試験導入提案の土台
* 前提：本書は「実装可能な範囲での最初の要件定義」であり、PoC結果・関係者レビューにより更新する。

---

## 1. 背景・目的

### 1.1 背景

* 生成AIの普及により、論文の文章生成自体は容易になった一方で、以下の問題が増えやすい。

  * 主張（Claim）と根拠（Evidence：図表・引用・実験条件）の紐付けが弱い
  * 比較・評価・再現性・制約（Limitations）が不足し、査読で手戻りが多い
  * 著者が説明できない（AI丸投げ）状態が起き、質が下がる
* 査読は通常、数日〜数週間のリードタイムがあり、投稿前に改善できれば往復回数を減らせる。

### 1.2 目的

* 投稿前に「Rejectの典型要因」を可視化・自律抽出し、著者が投稿前に修正できるようにする。
* 文章の自動生成ではなく、**論理・根拠・比較・制約の欠陥検出と、著者の理解（説明責任）担保**を重視する。
* ハッカソンでは「Agentic（自律的タスク分解）」と「技術的深さ（Claim–Evidence Map）」を明確に示す。

### 1.3 成果指標（KPI案）

* 主要KPI（MVP）

  * 根拠なしClaim検出数（検出→修正→減少が見える）
  * 修正ToDoの実行率（ユーザーが採用した提案数）
  * 口頭試問での“説明不能”指摘数の減少（2回目評価で改善）
* 拡張KPI（将来）

  * 査読コメント数・往復回数の減少（実データが取れる段階で）
  * 投稿から採択までの期間短縮（学会側と連携できた場合）

---

## 2. 対象範囲（スコープ）

### 2.1 対象

* 主対象：**IEICE（電子情報通信学会）レター相当**の短論文（短尺で構造が単純なためMVP向き）
* 入力形式（MVP）

  * 推奨：LaTeX（.tex + .bib + 図表ファイル）
  * 可能：PDF（ただし抽出精度の低下を許容／将来改善）
* 言語：日本語/英語（両対応を目標、MVPは日本語中心でも可）

### 2.2 非対象（MVPでやらない）

* 採択可否の判定（「この論文は採択/不採択」と断定する機能）
* 学会投稿システムへの直接統合（最初は著者側ツールとして提供）
* Google Scholar等の規約リスクが高い自動スクレイピング
* “AIっぽさ検知（生成AI判定）”のスコア化（炎上/誤判定リスクが高い）

---

## 3. ステークホルダー

* 主要ユーザー

  * 研究者（学生・社会人）、投稿予定者
* 二次ユーザー

  * 指導教員（研究室でのレビュー補助）
  * 共同著者（修正ToDoの共有）
* 運用者

  * 開発チーム（ハッカソンチーム）
  * 将来：学会運営/編集委員会（導入提案先）
* 利害関係

  * 著者の機密性（未公開研究情報）
  * 学会の公平性（査読への干渉回避）

---

## 4. 用語定義

* Claim：論文中の主張文（新規性、有効性、性能向上、優位性など）
* Evidence：Claimを支持する根拠（図表、実験条件、引用、数値、定理等）
* Claim–Evidence Map：ClaimとEvidenceの対応関係を可視化したマップ
* Preflight：投稿前チェック（形式・参照漏れ・最小要件）
* Oral Defense：口頭防衛（質問→回答→論文に書ける形への落とし込み）
* Agentic：エージェントが自律的にタスクを分解し、順に実行する挙動

---

## 5. システム概要

### 5.1 コンセプト

* 「執筆支援」ではなく「投稿前の模擬査読＋口頭防衛で論文を強くするゲートキーパー」
* 体験の主役は**攻め（論理・根拠の欠陥指摘）**
  守り（形式・参照）は裏側で静かに実施し、最終レポートに統合する。

### 5.2 構成（論理上のマルチエージェント）

* Logic Sentinel：具体性欠如・論理飛躍の検出（“AI臭さ”ではなく欠陥として）
* Evidence Auditor：Claim–Evidence Map生成、根拠断線の検出
* Prior-Art Coach：検索クエリ生成、Related Work差分表テンプレ提示
* Oral Examiner：弱点ベースの質問生成・追撃、回答から論文追記文の生成
* Orchestrator：上記を順序制御し、最終レポートを生成

---

## 6. 業務フロー（To-Be）

1. ユーザーが原稿をアップロード
2. システムが解析し、「致命傷トップ3」を提示
3. システムが口頭試問（テキスト中心）を開始
4. ユーザー回答から、論文に書ける追記文・修正候補（diff）を生成
5. 再スコアリングし改善を可視化
6. Pre-Review Report（提出前チェックレポート）を出力
7. 履歴として保存（任意）

---

## 7. 機能要件

> 表記：FR = Functional Requirement（機能要件）

### 7.1 アカウント・セッション

* **FR-001**：ユーザーはログイン無しでデモ利用できる（ハッカソン用）

  * ただし、保存機能を使う場合は識別子（簡易ログイン/トークン）を持てること。
* **FR-002**：ユーザーは「プロジェクト（論文）」単位でセッションを作成できる。
* **FR-003**：ユーザーは過去セッションのレポートと対話ログを閲覧できる（保存ONの場合）。

### 7.2 入力（アップロード）

* **FR-010**：LaTeX一式（tex/bib/fig）をアップロードできる。
* **FR-011**：PDFをアップロードできる（MVPは抽出精度低下を許容）。
* **FR-012**：ファイルサイズ上限を設定できる（例：合計50MB、PDFは20MB等）。
* **FR-013**：アップロード時に「言語」「投稿形式（Letter想定）」「分野タグ」を選択できる（任意）。

### 7.3 解析前処理（抽出・構造化）

* **FR-020**：論文から以下を抽出し構造化する

  * セクション構造（タイトル、見出し階層）
  * 図表一覧（番号、キャプション、参照箇所）
  * 引用一覧（本文中引用・bibエントリ）
  * 主要な数値表現（%改善、p値、N数、計算量など）
* **FR-021**：抽出結果を「解析データ」として保存できる（保存ONの場合）。

### 7.4 Silent Preflight（守り：裏側チェック）

* **FR-030**：参照漏れ検出

  * 図表が本文で参照されていない
  * 引用が本文で参照されていない / 本文引用が参考文献に無い
* **FR-031**：構造の最低要件チェック（MVP版）

  * Abstract/Introduction/Method/Experiment(or Evaluation)/Conclusion/Limitationsの有無（形式に応じて緩く判定）
* **FR-032**：形式・分量チェック（MVPは“注意”レベル）

  * ページ/文字数/図表過多などを警告として出す（断定はしない）
* **FR-033**：Preflight結果は最終レポートに統合するが、体験フローの冒頭では前面に出さない。

### 7.5 The Attack（攻め：論理・根拠の欠陥指摘）

* **FR-040**：致命傷トップ3（Rejectリスク上位3点）を自動提示する

  * 例：根拠なし主張が多い、比較が弱い、結論と課題設定がズレている等
* **FR-041**：Logic Sentinelは「具体性欠如」を検出する

  * 形容詞・断定表現があるが数値/条件/比較/引用が近傍にない箇所
* **FR-042**：Evidence AuditorはClaim–Evidence Mapを生成する

  * Claim抽出（例：「提案法は〜より優れる」「新規性がある」等）
  * Evidence候補抽出（図表、引用、評価指標、実験条件）
  * 紐付け（根拠が無い/弱い/遠いを分類）
* **FR-043**：Prior-Art Coachは自動スクレイピング無しで、検索クエリ案（日本語/英語）と差分表テンプレを提示する。

### 7.6 Oral Defense（口頭試問：理解を担保）

* **FR-050**：Oral Examinerは弱点に基づいた質問を生成し、対話で問い詰める（テキスト）
* **FR-051**：ユーザー回答が曖昧な場合、追撃質問を生成する（最低1回）
* **FR-052**：ユーザー回答を「論文に書ける表現」に変換して、追記文案を提示する

  * 重要：AIが“勝手に作る”のではなく、「あなたの回答を反映するとこう書ける」という形にする
* **FR-053**：（加点要素）デモ用に1問のみ音声で口頭試問を実行できるモードを用意する（任意）。

### 7.7 Patch（差分）生成

* **FR-060**：修正候補を差分（diff）形式で提示する（LaTeX優先）
* **FR-061**：修正ToDoをImpact×Effortで順位付けして提示する（Top10）
* **FR-062**：ユーザーは提案を採用/却下でき、採用した提案は履歴に残せる（保存ONの場合）

### 7.8 レポート出力

* **FR-070**：Pre-Review Reportを生成する（HTML/PDF）

  * Preflight結果
  * 致命傷トップ3
  * Claim–Evidence Map
  * 修正ToDo Top10
  * Related Work差分表テンプレ
  * Oral Defenseログ（要点のみ）
* **FR-071**：レポートはダウンロード可能とする。

### 7.9 管理・運用（最低限）

* **FR-080**：運用者はエラーログ・実行時間・トークン消費（概算）を確認できる。
* **FR-081**：悪用・過負荷対策としてレート制限を行う。

---

## 8. 非機能要件

### 8.1 性能・応答

* **NFR-001**：アップロード〜初回「致命傷トップ3」提示まで：目標60秒以内（MVP）
* **NFR-002**：口頭試問1ターン：目標10〜15秒以内（モデル呼び出し含む）
* **NFR-003**：同時利用（デモ）：最低10セッションの同時実行に耐える（軽量構成）

### 8.2 可用性

* **NFR-010**：ハッカソン期間中は稼働率99%目標（厳密なSLAは不要）
* **NFR-011**：障害時は「解析途中でも保存済み部分を返す」など部分劣化を許容

### 8.3 セキュリティ・プライバシー（重要）

* **NFR-020**：未公開研究情報のため、データは暗号化して保存（保存する場合）
* **NFR-021**：データ保持期間を設定できる（例：24時間/7日/即時削除）

  * デモはデフォルト短め推奨
* **NFR-022**：モデル入力データの取り扱い方針を明示（ログ最小化、学習利用しない設定を目標）
* **NFR-023**：ユーザーが「保存しない（セッション終了で削除）」を選べる
* **NFR-024**：外部送信の範囲（どのサービスに何を送るか）をUIで説明する

### 8.4 品質

* **NFR-030**：ハルシネーション対策

  * 「引用の実在」「外部論文の存在」など断定を避け、ユーザー確認を促す
  * 根拠箇所（段落ID/図番号/引用キー）を必ず添える
* **NFR-031**：説明可能性

  * どの文がClaimで、どこがEvidenceかを追跡可能にする

### 8.5 コスト

* **NFR-040**：1セッション当たりの推定コスト上限（目標）を設定し、超過時は軽量モードに落とす（モデル切替、要約強制等）

---

## 9. データ要件

### 9.1 保存データ（例：Firestore）

* Users（任意）：user_id, 作成日時, 設定（保持期間等）
* Projects：project_id, user_id, タイトル, 分野タグ
* Submissions：submission_id, project_id, ファイル参照, 版番号, 作成日時
* Analysis：

  * sections（見出し階層）
  * figures/tables（番号・キャプション・参照箇所）
  * citations（本文引用・bib）
  * claims（Claimリスト、位置情報）
  * evidence_links（Claim↔Evidenceの紐付け）
  * risks（致命傷トップ3）
* Conversations：turns（質問、回答、追記文案、採否）
* Reports：report_id, 生成物リンク, 要約, スコア

### 9.2 保存データ（Cloud Storage）

* raw_uploads/
* parsed_text/
* reports/
* diffs/

---

## 10. 外部インターフェース要件

### 10.1 UI画面（最低限）

* UI-01：アップロード画面（形式選択、分野タグ、保存ON/OFF）
* UI-02：解析状況（進捗表示）
* UI-03：結果サマリ（致命傷トップ3、スコア）
* UI-04：Claim–Evidence Map表示（グラフ/表）
* UI-05：口頭試問（チャットUI、任意で音声1問）
* UI-06：ToDo Top10（優先度、採用/却下）
* UI-07：レポート出力（ダウンロード）

### 10.2 API（例：Cloud Run）

* POST /upload
* POST /analyze
* GET /analysis/{id}
* POST /oral/ask
* POST /patch/generate
* GET /report/{id}

---

## 11. 技術要件（Google Cloud前提）

* 実行基盤：Cloud Run（オーケストレーター兼API）
* 生成AI：Vertex AI（Gemini系モデル）
* ストレージ：Cloud Storage
* セッション/メタデータ：Firestore
* 監視：Cloud Logging / Cloud Monitoring
* 認証（任意）：Firebase Auth（将来）
* 音声（任意・デモ用）：Speech-to-Text / Text-to-Speech もしくは会話基盤

---

## 12. 制約条件

* 学会・出版社のポリシーは変動し得るため、MVPでは「参照リンク提示＋テンプレ生成」までに留める（断定しない）。
* PDF抽出は誤り得るため、MVPはLaTeX推奨とし、PDFは“ベータ扱い”で注記する。
* 外部論文検索は規約・再現性・誤検出のリスクがあるため、MVPは「検索クエリ生成＋差分表テンプレ」に限定。

---

## 13. 受入基準（Acceptance Criteria）

### 13.1 MVP合格条件（必須）

* AC-01：LaTeX入力で、セクション/図表/引用が抽出できる
* AC-02：致命傷トップ3が出る（少なくとも根拠不足・比較不足・整合性のいずれかを指摘）
* AC-03：Claim–Evidence Mapが生成され、根拠なしClaimを最低5件以上検出できる（ダミー論文で再現）
* AC-04：口頭試問が弱点に基づいて10問生成され、ユーザー回答から追記文案が出る
* AC-05：ToDo Top10がImpact×Effortで順位付きで出る
* AC-06：レポート（HTML/PDF）が出力できる

### 13.2 デモ合格条件（審査員向け）

* AC-D1：Before/Afterで「根拠なしClaim数」や「整合性指標」が改善して見える
* AC-D2：口頭試問が“査読っぽく痛い質問”になっている（台本なしでも成立）

---

## 14. リスクと対策

* R-01：LLMの誤指摘（ハルシネーション）

  * 対策：根拠箇所（段落/図/引用キー）を必須化、断定を避ける
* R-02：機密情報漏えい懸念

  * 対策：保存OFFデフォルト、保持期間短、ログ最小化、暗号化
* R-03：PDF抽出が不安定

  * 対策：LaTeX優先、PDFはベータ、抽出結果のユーザー確認UI
* R-04：音声がデモで事故る

  * 対策：MVPはテキスト、音声は1問のみ＆失敗時はテキストへフォールバック

---

## 15. 開発マイルストーン（参考）

* M0：入力（LaTeX）→抽出→構造化
* M1：Evidence Auditor（Claim–Evidence Map）最小実装
* M2：致命傷トップ3＋ToDo Top10
* M3：口頭試問（テキスト）＋追記文案（diff）
* M4：レポート生成＋UI統合
* M5：デモ演出（Reviewer #2 Mode / 音声1問）

---

必要なら次に、上の要件定義に直結する形で

* **画面遷移図（UIワイヤー）**
* **データモデル（Firestoreの具体スキーマ）**
* **各エージェントの入出力仕様（JSONスキーマ）**
* **受入テスト項目表（テストケース）**
  まで一気に作れます。
